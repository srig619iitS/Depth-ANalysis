Image processing or more specifically, digital image processing is a process by which a digital image image is processed using a set of algorithms. Involves tasks like noise removal to common tasks like identifying objects, persons, text etc to more complicated tasks like image classification, emotion detection, anomaly detection, segementation.
Digital image processing using Neural networks was a popular choice, lets explore image segmentation
A digital image is made up of various components that need to be analysed and analysis performed on such components can reveal a lot of hidden information from them. Image processing can help in solving plethora of business problems
Image segementation is a process of segregating a digital image into various subgroups of pixels cal+
led image objects, which can reduce the complexity of the image, and thus analysing the image becomes simpler. 
They are various image segmentation algorithms to split and group a certain set of pixels  under a category where they have some or the other thing common in them. Using these labels, we can specify boundaries, draw lines, and separate the most required objects in an image from the rest of not-so-important ones. 
What problems are solved by image segmentation
A facial recognition system implements image segmentation, identifying an employee and enabling them to mark their attendance automatically. 
Segmentation in image processing is being used in the medical industry for efficient and faster diagnosis, detecting diseases, tumors, and cell and tissue patterns from various medical imagery generated from radiography, MRI, endoscopy, thermography, ultrasonography etc.
Satellite images are processed to identify various patterns, objects, geographical contours, soil information etc. which can be later used for agriculture, mining, geo-sensing etc.
Image segmentation has a massive application area in robotics, RPA, self-driving cars, etc.
Security images can be processed to detect harmful objects, threats, people and incidents.
Collecting similar pixels tgether based on image properties is done by
	Similarity Detection (Region Approach): Relies on detecting similar pixels in an image - based on threshold, region growing, region spreading and region merging. 
	Discontinuity Detection (Boundary approach) - Opposite of similarity detection approach where algorithm rather search for discontinuity. Image segmentation algorithms like edge detection, point detection, line detection follows this approach - where edges get detected based on various metrics of discontinuity like intensity etc.
Types of techniques: based on the above two approaches, these techniques are employed based on the type of image that needs to be processed and analysed and can be classified into three broader categories.
	Structural Segmentation Techniques: It requires firstly, know the structural information about the image under the scanner. Like Pixels, pixel density, distributions, histograms, color distribution etc. Second, we need to have the structural information about the region that we are about to fetch from the image. This section deals with identifying our target area, which is highly specific to the business problem that we are trying to solve. Similarity based approach.

	Stochastic Segmentation Techniques: The primary information that is required for them is to know the discrete pixel values of the full image, rather than pointing out the structure of the required portion of the image. ANN and machine learning based algorithms that use K-means make use of this approach
Hybrid Techniques: As the name suggests, its combination of structural and stochastic methods. 
Techniques: Threshold Method; Edge based segmentation, region based segmentation, clustering based segmentation, watershed based method, ANN based segmentation.

Threshold method:
	from transformers import pipeline
	from PIL import Image
	import cv2
	import numpy as np
	from matplotlib import pyplot as plt
#open the image
	im = Image.open("/Object.jpg")
	image = np.array(im)
	image
# 1. Simple Thresholding
_, simple_threshold = cv2.threshold(image, 128, 255, cv2.THRESH_BINARY)
print("Simple Threshold Value:", 128)

# 2. Otsu's Binarization
image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
_, otsu_threshold = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
print("Otsu's Threshold Value:", _)

# 3. Adaptive Thresholding
adaptive_threshold = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                           cv2.THRESH_BINARY, 11, 2)
print("Adaptive Thresholding - Gaussian C: 11x11, Constant 2")
# Original Image and Histogram
	plt.subplot(3, 2, 1), plt.imshow(image, cmap='gray')
	plt.title('Original Image'), plt.xticks([]), plt.yticks([])
	plt.subplot(3, 2, 2), plt.hist(image.ravel(), 256, [0, 256], color='r', alpha=0.75)
	plt.title('Original Image Histogram')

# Simple Thresholding and Histogram
	plt.subplot(3, 2, 3), plt.imshow(simple_threshold, cmap='gray')
	plt.title('Simple Thresholding'), plt.xticks([]), plt.yticks([])
	plt.subplot(3, 2, 4), plt.hist(simple_threshold.ravel(), 256, [0, 256], color='r', alpha=0.75)
	plt.title('Simple Thresholding Histogram')

# Otsu's Binarization and Histogram
	plt.subplot(3, 2, 5), plt.imshow(otsu_threshold, cmap='gray')
	plt.title("Otsu's Binarization"), plt.xticks([]), plt.yticks([])
	plt.subplot(3, 2, 6), plt.hist(otsu_threshold.ravel(), 256, [0, 256], color='r', alpha=0.75)
	plt.title("Otsu's Binarization Histogram")

	plt.tight_layout()
	plt.show()

Edge Based Segmentation
Edge detection is a process of locating edges in an image understanding image features. Edges possess meaningful features and significant information. It processes and filters out information that may be regarded as less relevant, preserving and focusing solely on the important structural properties of an image. This technique detects edges based on various discontinuities in grey level, color texture, brightness, saturation, contrast etc (EDGE DETECTION ALGORITHMS).
To further enhance the results, supplementary processing steps like concatenating all the edges into edge chains that correspond better with borders in the image.
Edge detection operators are discrete differentiation operators, computing an approximation of the gradient of the image intensity function. 
Gradient based operator: First order derivatives sobel operator, prewitt operator
Gaussian based operator: Canny edge detector, laplacian of gaussian.
 Edge detection algorithms primarily fall into two categories - Gradient based methods and gray histograms. Operators in edge detection algorithms like sobel operator, canny, robert's  variable are used to detecting the edge discontinuities and mark the edge boundaries. The end goal is to reach atleast a partial segmentation using this process, where we group all the local edges into a new binary image where only edge chains that match the required existing objects or image parts are present.


Prewitt operator: 

#Edge detection
	from transformers import pipeline
	from PIL import Image
	import cv2
	import numpy as np
	from matplotlib import pyplot as plt

#open the image
	im = cv2.imread("/Object.jpg")

# Convert the image to grayscale if it's in RGB format
	gray_image = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)

# Prewitt operator kernels - prewitt_kx and prewitt_ky are kernels used for Prewitt edge detection.
#These kernels are convolution filters that are applied to the image to compute the gradient in the horizontal (x)
# and vertical (y) directions
	rewitt_kx = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]], dtype=np.float32)
	rewitt_ky = np.array([[1, 1, 1], [0, 0, 0], [-1, -1, -1]], dtype=np.float32)

# Apply Prewitt operators - obtain the gradient images in the x and y directions,
# These gradient images represent the rate of change of intensity in the corresponding directions.
	rewitt_x = cv2.filter2D(gray_image, cv2.CV_64F, prewitt_kx)
	rewitt_y = cv2.filter2D(gray_image, cv2.CV_64F, prewitt_ky)

# Compute the magnitude of the gradient - The magnitude of the gradient is calculated by taking
# the absolute values of the gradients in the x and y directions and summing them element-wise.
	rewitt_magnitude = np.abs(prewitt_x) + np.abs(prewitt_y)
# Display the results
	plt.figure(figsize=(12, 6))
	plt.subplot(1, 4, 1), plt.imshow(gray_image, cmap='gray')
	plt.title('Original Image'), plt.xticks([]), plt.yticks([])

# Add this line to display the grayscale image
	plt.subplot(1, 4, 2), plt.imshow(prewitt_x, cmap='gray')
	plt.title('Prewitt X'), plt.xticks([]), plt.yticks([])
	plt.subplot(1, 4, 3), plt.imshow(prewitt_y, cmap='gray')
	plt.title('Prewitt Y'), plt.xticks([]), plt.yticks([])
	plt.subplot(1, 4, 4), plt.imshow(prewitt_magnitude, cmap='gray')
	plt.title('Prewitt Magnitude'), plt.xticks([]), plt.yticks([])
	plt.show()


# Sobel Operator
sobel_x = cv2.Sobel(gray_image, cv2.CV_64F, 1, 0, ksize=3)
sobel_y = cv2.Sobel(gray_image, cv2.CV_64F, 0, 1, ksize=3)

sobel_magnitude = np.abs(sobel_x) + np.abs(sobel_y)

# Scharr Operator
scharr_x = cv2.Scharr(gray_image, cv2.CV_64F, 1, 0)
scharr_y = cv2.Scharr(gray_image, cv2.CV_64F, 0, 1)

scharr_magnitude = np.abs(scharr_x) + np.abs(scharr_y)

# Display the results
plt.figure(figsize=(12, 8))
plt.subplot(2, 4, 1), plt.imshow(gray_image, cmap='gray')
plt.title('Original Image'), plt.xticks([]), plt.yticks([])
plt.subplot(2, 4, 2), plt.imshow(sobel_x, cmap='gray')
plt.title('Sobel X'), plt.xticks([]), plt.yticks([])
plt.subplot(2, 4, 3), plt.imshow(sobel_y, cmap='gray')
plt.title('Sobel Y'), plt.xticks([]), plt.yticks([])
plt.subplot(2, 4, 4), plt.imshow(sobel_magnitude, cmap='gray')
plt.title('Sobel Magnitude'), plt.xticks([]), plt.yticks([])
plt.subplot(2, 4, 2), plt.imshow(scharr_x, cmap='gray')
plt.title('scharr_x'), plt.xticks([]), plt.yticks([])
plt.subplot(2, 4, 3), plt.imshow(scharr_y, cmap='gray')
plt.title('scharr_y'), plt.xticks([]), plt.yticks([])
plt.subplot(2, 4, 8), plt.imshow(scharr_magnitude, cmap='gray')
plt.title('Scharr Magnitude'), plt.xticks([]), plt.yticks([])
plt.show()

Cv2 library sobel operator computes the gradients of the image. It performs convolution with sobel kernel to calculate x-gradient and Y - gradient.
takes input gray scale image and specifies the output data type as 64-bit floating point for more precision. 1,0 sobel function indicate order of derivative
in the X and Y direction. ksize = 3 is sobel kernel (3X3). Computes the magnitude of the gradient by adding the absolute values of the X and Y gradients. 

Scharr Operator: Scharr operator uses different kernel which provides better rotational symmetry. Computes the magnitude of the gradient using the scharr operator.


